{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import Libraries","metadata":{}},{"cell_type":"markdown","source":"#### Change from version 1: We will be using the RAPIDS architecture to make use of the GPU environment","metadata":{}},{"cell_type":"code","source":"# Basic\nimport numpy as np\nimport pandas as pd\nimport os\nimport pyarrow\nfrom datetime import datetime\nfrom datetime import datetime, date\nimport joblib\nimport csv\nimport math\nimport pickle\nfrom scipy import stats\nimport numpy as np\nimport statistics as st\nimport gc\nfrom IPython.display import clear_output\n\n# ML scikit-learn\nimport sklearn as sk\nfrom sklearn.base import TransformerMixin, BaseEstimator\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import ParameterGrid, KFold\n\n# XGBoost\nimport xgboost as xgb\nimport optuna","metadata":{"execution":{"iopub.status.busy":"2022-06-23T07:21:39.746771Z","iopub.execute_input":"2022-06-23T07:21:39.747732Z","iopub.status.idle":"2022-06-23T07:21:40.601826Z","shell.execute_reply.started":"2022-06-23T07:21:39.747688Z","shell.execute_reply":"2022-06-23T07:21:40.600987Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Additional GPU libraries\nimport cudf\nimport cupy\nimport cuml\nfrom cuml.model_selection import GridSearchCV, train_test_split\ncudf.set_allocator(\"managed\")","metadata":{"execution":{"iopub.status.busy":"2022-06-23T07:21:40.603749Z","iopub.execute_input":"2022-06-23T07:21:40.604147Z","iopub.status.idle":"2022-06-23T07:21:41.957953Z","shell.execute_reply.started":"2022-06-23T07:21:40.604105Z","shell.execute_reply":"2022-06-23T07:21:41.957133Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Section 1: Create functions and pipeline classes","metadata":{}},{"cell_type":"code","source":"def stringToDate(X, date_col):\n    \n    # convert column to date time\n    X[date_col] = cudf.to_datetime(X[date_col], infer_datetime_format = True)\n        \n    # return df\n    return X","metadata":{"execution":{"iopub.status.busy":"2022-06-23T07:21:41.960301Z","iopub.execute_input":"2022-06-23T07:21:41.960682Z","iopub.status.idle":"2022-06-23T07:21:41.966230Z","shell.execute_reply.started":"2022-06-23T07:21:41.960646Z","shell.execute_reply":"2022-06-23T07:21:41.965373Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def createFeatures(X, cat_cols, num_cols):\n    \n    # sort dataframe\n    X = X.sort_values(by = ['customer_ID', 'S_2'], ascending = False)\n        \n    ## create features from numeric cols\n    X_num = X.groupby(\"customer_ID\", as_index = False)[num_cols].agg(['mean', 'median', 'std', 'min', 'max', 'last', 'first'])\n    X_num.columns = ['_'.join(x) for x in X_num.columns]\n    X_num = X_num.reset_index()\n    \n    # fill na values\n    num_cols = [col for col in X_num.columns if col not in ['customer_ID']]\n    for col in num_cols:\n        X_num[col].fillna(X_num[col].mean().astype(cupy.float32), inplace = True)\n    \n\n    ## create features from categorical cols\n    X_cat = X.groupby(\"customer_ID\", as_index = False)[cat_cols].agg(['count', 'last', 'first', 'nunique'])\n    X_cat.columns = ['_'.join(x) for x in X_cat.columns]\n    X_cat = X_cat.reset_index()\n    \n    # fill na values\n    cat_cols = [col for col in X_cat.columns if col not in ['customer_ID']]\n    for col in cat_cols:\n        X_cat[col].fillna(stats.mode(X_cat[col].to_pandas(),nan_policy = 'omit')[0][0], inplace = True)\n        \n        \n    # merge the dataframes\n    X_updated = cudf.merge(X_num, X_cat, on = 'customer_ID', how = 'outer')\n    \n    # fill na after merging\n    X_updated.fillna(method = 'ffill', inplace = True)\n    X_updated.fillna(method = 'bfill', inplace = True)\n        \n    # remove intermediate dfs\n    del X_num, X_cat\n        \n    # return updated df\n    return X_updated    ","metadata":{"execution":{"iopub.status.busy":"2022-06-23T07:21:41.968764Z","iopub.execute_input":"2022-06-23T07:21:41.969427Z","iopub.status.idle":"2022-06-23T07:21:41.982325Z","shell.execute_reply.started":"2022-06-23T07:21:41.969382Z","shell.execute_reply":"2022-06-23T07:21:41.981596Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Section 2: Read Data","metadata":{}},{"cell_type":"code","source":"# initialize project directory\nproject_dir = '/kaggle'","metadata":{"execution":{"iopub.status.busy":"2022-06-23T07:21:41.983449Z","iopub.execute_input":"2022-06-23T07:21:41.983872Z","iopub.status.idle":"2022-06-23T07:21:41.995690Z","shell.execute_reply.started":"2022-06-23T07:21:41.983835Z","shell.execute_reply":"2022-06-23T07:21:41.994591Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# list file names in input directory\nfor dirname, _, filenames in os.walk(os.path.join(project_dir, 'input')):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2022-06-23T07:21:41.997055Z","iopub.execute_input":"2022-06-23T07:21:41.997492Z","iopub.status.idle":"2022-06-23T07:21:42.037460Z","shell.execute_reply.started":"2022-06-23T07:21:41.997450Z","shell.execute_reply":"2022-06-23T07:21:42.036717Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"/kaggle/input/model-xgb-v2/model_xbg_v2.pkl\n/kaggle/input/model-xgb-v3/model_xbg_v2.json\n/kaggle/input/amex-data-integer-dtypes-parquet-format/train.parquet\n/kaggle/input/amex-data-integer-dtypes-parquet-format/test.parquet\n/kaggle/input/amex-prediction-model-xgb/model_xgb.json\n/kaggle/input/model-xgb-20220616/model_xgb_20220616.json\n/kaggle/input/amex-default-prediction-v1/__results__.html\n/kaggle/input/amex-default-prediction-v1/__notebook_source__.ipynb\n/kaggle/input/amex-default-prediction-v1/__notebook__.ipynb\n/kaggle/input/amex-default-prediction-v1/__output__.json\n/kaggle/input/amex-default-prediction-v1/custom.css\n/kaggle/input/amex-default-prediction/sample_submission.csv\n/kaggle/input/amex-default-prediction/train_data.csv\n/kaggle/input/amex-default-prediction/test_data.csv\n/kaggle/input/amex-default-prediction/train_labels.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"## path to files\n# Train\ntrain_X_path = '/kaggle/input/amex-data-integer-dtypes-parquet-format/train.parquet'\ntrain_y_path = '/kaggle/input/amex-default-prediction/train_labels.csv'\n\n# Test\ntest_X_path = '/kaggle/input/amex-data-integer-dtypes-parquet-format/test.parquet'","metadata":{"execution":{"iopub.status.busy":"2022-06-23T07:21:42.038692Z","iopub.execute_input":"2022-06-23T07:21:42.039267Z","iopub.status.idle":"2022-06-23T07:21:42.043510Z","shell.execute_reply.started":"2022-06-23T07:21:42.039228Z","shell.execute_reply":"2022-06-23T07:21:42.042760Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# read train data\ndf_train_X = cudf.read_parquet(train_X_path)","metadata":{"execution":{"iopub.status.busy":"2022-06-23T07:21:42.044856Z","iopub.execute_input":"2022-06-23T07:21:42.045312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# view sample\nprint(df_train_X.shape)\ndf_train_X.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Section 3: Feature engineering","metadata":{}},{"cell_type":"code","source":"# no of folds\nFOLDS = 5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# initialize relevant cols\nall_cols = [c for c in list(df_train_X.columns) if c not in ['customer_ID','S_2']]\n\ncat_features = [\"B_30\",\"B_38\",\"D_114\",\"D_116\",\"D_117\",\"D_120\",\"D_126\",\"D_63\",\"D_64\",\"D_66\",\"D_68\"]\nnum_features = [col for col in all_cols if col not in cat_features]\n\ndate_field = 'S_2'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# step 1: change date string to date\ndf_train_X = stringToDate(df_train_X, date_field)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# step 2: create features\ndf_train_X = createFeatures(df_train_X, cat_features, num_features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sort data\ndf_train_X = df_train_X.sort_values(by = 'customer_ID')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# view sample\nprint(df_train_X.shape)\ndf_train_X.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Section 4: Train Models","metadata":{}},{"cell_type":"markdown","source":"### Read labels","metadata":{}},{"cell_type":"code","source":"# read data\ndf_train_y = cudf.read_csv(train_y_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sort updated df by customer id\ndf_train_y = df_train_y.sort_values(by = 'customer_ID')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df_train_y.shape)\ndf_train_y.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_y['target'].value_counts() / df_train_y.shape[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# merge with X\ndf_train = cudf.merge(df_train_X, df_train_y, on = 'customer_ID', how = 'left')\nprint(df_train.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train validation split\nX_train, X_val, y_train, y_val = train_test_split(X = df_train.drop(columns = ['target']),\n                                                  y = df_train['target'],\n                                                  test_size = 0.25, random_state = 42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check incidence rate\nprint(y_train.sum() / y_train.count(), y_val.sum() / y_val.count())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function for custom evaulation metric for the amex competition (specifically for xgboost)\ndef amex_metric_xgboost(predt: np.ndarray, dtrain: xgb.DMatrix):\n    \n    # convert to pandas dataframe\n    y_true = pd.DataFrame(data = {'target' : dtrain.get_label()})\n    y_pred = pd.DataFrame(data = {'prediction' : predt})\n\n    def top_four_percent_captured(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n        df = pd.concat([y_true, y_pred], axis = 'columns').sort_values('prediction', ascending=False)\n        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n        four_pct_cutoff = int(0.04 * df['weight'].sum())\n        df['weight_cumsum'] = df['weight'].cumsum()\n        df_cutoff = df.loc[df['weight_cumsum'] <= four_pct_cutoff]\n        return (df_cutoff['target'] == 1).sum() / (df['target'] == 1).sum()\n        \n    def weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n        df = pd.concat([y_true, y_pred], axis = 'columns').sort_values('prediction', ascending=False)\n        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n        df['random'] = (df['weight'] / df['weight'].sum()).cumsum()\n        total_pos = (df['target'] * df['weight']).sum()\n        df['cum_pos_found'] = (df['target'] * df['weight']).cumsum()\n        df['lorentz'] = df['cum_pos_found'] / total_pos\n        df['gini'] = (df['lorentz'] - df['random']) * df['weight']\n        return df['gini'].sum()\n\n    def normalized_weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n        y_true_pred = y_true.rename(columns={'target': 'prediction'})\n        return weighted_gini(y_true, y_pred) / weighted_gini(y_true, y_true_pred)\n\n    g = normalized_weighted_gini(y_true, y_pred)\n    d = top_four_percent_captured(y_true, y_pred)\n\n    return ('Amex_Metric', 0.5 * (g + d))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # function for custom evaulation metric for the amex competition (generic)\n# def amex_metric_generic(y_true: cupy.ndarray, y_pred: cupy.ndarray):\n    \n#     # convert to pandas dataframe\n#     y_true = cudf.DataFrame(data = {'target' : y_true}).to_pandas()\n#     y_pred = cudf.DataFrame(data = {'prediction' : y_pred}).to_pandas()\n\n#     def top_four_percent_captured(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n#         df = pd.concat([y_true, y_pred], axis = 'columns').sort_values('prediction', ascending=False)\n#         df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n#         four_pct_cutoff = int(0.04 * df['weight'].sum())\n#         df['weight_cumsum'] = df['weight'].cumsum()\n#         df_cutoff = df.loc[df['weight_cumsum'] <= four_pct_cutoff]\n#         return (df_cutoff['target'] == 1).sum() / (df['target'] == 1).sum()\n        \n#     def weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n#         df = pd.concat([y_true, y_pred], axis = 'columns').sort_values('prediction', ascending=False)\n#         df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n#         df['random'] = (df['weight'] / df['weight'].sum()).cumsum()\n#         total_pos = (df['target'] * df['weight']).sum()\n#         df['cum_pos_found'] = (df['target'] * df['weight']).cumsum()\n#         df['lorentz'] = df['cum_pos_found'] / total_pos\n#         df['gini'] = (df['lorentz'] - df['random']) * df['weight']\n#         return df['gini'].sum()\n\n#     def normalized_weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n#         y_true_pred = y_true.rename(columns={'target': 'prediction'})\n#         return weighted_gini(y_true, y_pred) / weighted_gini(y_true, y_true_pred)\n\n#     g = normalized_weighted_gini(y_true, y_pred)\n#     d = top_four_percent_captured(y_true, y_pred)\n    \n#     amex_metric = 0.5 * (g + d)\n    \n#     return amex_metric","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.1 XGBoost","metadata":{}},{"cell_type":"markdown","source":"#### 4.1.1 Train single model using sklearn API","metadata":{}},{"cell_type":"code","source":"# initialize param grid\nparam_grid_xgb = {'n_estimators' : [100],\n                  'max_depth' : [1],\n                  'subsample' : [0.5],\n                  'learning_rate' : [0.05],\n                  'colsample_bytree' : [0.5]}","metadata":{"execution":{"iopub.status.busy":"2022-06-23T07:07:46.330935Z","iopub.execute_input":"2022-06-23T07:07:46.33129Z","iopub.status.idle":"2022-06-23T07:07:46.336444Z","shell.execute_reply.started":"2022-06-23T07:07:46.331261Z","shell.execute_reply":"2022-06-23T07:07:46.335296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model obect\nmodel_xgb = xgb.XGBClassifier(objective = 'binary:logistic',\n                              predictor = 'gpu_predictor',\n                              tree_method = 'gpu_hist',\n                              sampling_method = 'gradient_based',\n                              verbosity = 2)","metadata":{"execution":{"iopub.status.busy":"2022-06-23T07:07:47.901086Z","iopub.execute_input":"2022-06-23T07:07:47.901464Z","iopub.status.idle":"2022-06-23T07:07:47.90615Z","shell.execute_reply.started":"2022-06-23T07:07:47.901432Z","shell.execute_reply":"2022-06-23T07:07:47.905323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# grid search\ngrid_search_xgb = GridSearchCV(estimator = model_xgb,\n                               param_grid = param_grid_xgb,\n                               cv = 5,\n                               verbose = 2)","metadata":{"execution":{"iopub.status.busy":"2022-06-23T07:07:49.681809Z","iopub.execute_input":"2022-06-23T07:07:49.682744Z","iopub.status.idle":"2022-06-23T07:07:49.687363Z","shell.execute_reply.started":"2022-06-23T07:07:49.682706Z","shell.execute_reply":"2022-06-23T07:07:49.686228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_search_xgb.fit(X = X_train.drop(columns = 'customer_ID').to_pandas(),\n                    y = cupy.asarray(y_train).get())","metadata":{"execution":{"iopub.status.busy":"2022-06-23T07:07:51.570464Z","iopub.execute_input":"2022-06-23T07:07:51.571204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 4.1.1 Train single model","metadata":{}},{"cell_type":"code","source":"# convert data to DMatrix\ndtrain = xgb.DMatrix(X_train.drop(columns = 'customer_ID'), \n                     label = y_train)\n\ndval = xgb.DMatrix(X_val.drop(columns = 'customer_ID'), \n                   label = y_val)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T06:22:24.149511Z","iopub.execute_input":"2022-06-22T06:22:24.149933Z","iopub.status.idle":"2022-06-22T06:22:27.616955Z","shell.execute_reply.started":"2022-06-22T06:22:24.1499Z","shell.execute_reply":"2022-06-22T06:22:27.616157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train the model\nmodel_xgb = xgb.train(params = {'tree_method' : 'gpu_hist',\n                                'objective': 'binary:logistic',\n                                'verbosity' : 2,\n                                'max_depth' : 3,\n                                'subsample' : 0.5,\n                                'eta' : 0.05,\n                                'sampling_method' : 'gradient_based',\n                                'colsample_bytree' : 0.5,\n                                'predictor':'gpu_predictor',\n                                'disable_default_eval_metric' : 1},\n                      dtrain = dtrain,\n                      num_boost_round = 7000,\n                      evals = [(dtrain, 'train'),\n                               (dval, 'validation')],\n                      early_stopping_rounds = 100,\n                      verbose_eval = 100,\n                      custom_metric = amex_metric_xgboost,\n                      maximize = True)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T06:22:27.618823Z","iopub.execute_input":"2022-06-22T06:22:27.619174Z","iopub.status.idle":"2022-06-22T06:24:10.167407Z","shell.execute_reply.started":"2022-06-22T06:22:27.619139Z","shell.execute_reply":"2022-06-22T06:24:10.166743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check model attributes\nmodel_xgb.attributes()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save the model\nmodel_xgb.save_model(f\"model_xgb_{date.today()}.json\")","metadata":{"execution":{"iopub.status.busy":"2022-06-22T06:24:10.180005Z","iopub.execute_input":"2022-06-22T06:24:10.180407Z","iopub.status.idle":"2022-06-22T06:24:10.188084Z","shell.execute_reply.started":"2022-06-22T06:24:10.180358Z","shell.execute_reply":"2022-06-22T06:24:10.18739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 4.1.2 Train multiple models using K-fold strategy","metadata":{}},{"cell_type":"code","source":"# initialize the folds\nkf = KFold(n_splits = FOLDS, shuffle = True, random_state = 42)\nkfolds =  kf.split(df_train)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T06:31:56.499686Z","iopub.execute_input":"2022-06-22T06:31:56.500483Z","iopub.status.idle":"2022-06-22T06:31:56.505237Z","shell.execute_reply.started":"2022-06-22T06:31:56.500442Z","shell.execute_reply":"2022-06-22T06:31:56.504267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train k models over k folds\n\nevals = {}\n\n\nfor k, (train_idx, val_idx) in enumerate(kfolds):\n    \n    # create training datasets\n    X_train = df_train.loc[train_idx].drop(columns = ['target'])\n    y_train = df_train.loc[train_idx, 'target']\n    \n    # create vvalidation datasets\n    X_val = df_train.loc[val_idx].drop(columns = ['target'])\n    y_val = df_train.loc[val_idx, 'target']\n    \n    # convert datasets to DMatrix\n    dtrain = xgb.DMatrix(X_train.drop(columns = 'customer_ID'), \n                         label = y_train)\n\n    dval = xgb.DMatrix(X_val.drop(columns = 'customer_ID'), \n                       label = y_val)\n    \n    # print status\n    clear_output(wait = True)\n    print(f'###########  Training model {k+1}  ###########')\n    \n    # train the model\n    model_xgb = xgb.train(params = {'tree_method' : 'gpu_hist',\n                                    'objective': 'binary:logistic',\n                                    'verbosity' : 2,\n                                    'max_depth' : 3,\n                                    'subsample' : 0.5,\n                                    'eta' : 0.05,\n                                    'sampling_method' : 'gradient_based',\n                                    'colsample_bytree' : 0.5,\n                                    'predictor':'gpu_predictor',\n                                    'disable_default_eval_metric' : 1},\n                          dtrain = dtrain,\n                          num_boost_round = 2000,\n                          evals = [(dtrain, 'train'),\n                                   (dval, 'validation')],\n                          early_stopping_rounds = 100,\n                          verbose_eval = 100,\n                          custom_metric = amex_metric_xgboost,\n                          maximize = True)\n    \n    # save the model\n    model_xgb.save_model(f\"model_xgb_fold_{k+1}_{date.today()}.json\")\n    \n    \n    # update evals dict\n    evals[k+1] = float(model_xgb.attributes().get('best_score'))\n\n    # free up memory\n    del X_train, y_train, X_val, y_val, dtrain, dval\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-22T06:32:02.363296Z","iopub.execute_input":"2022-06-22T06:32:02.363657Z","iopub.status.idle":"2022-06-22T08:28:46.117077Z","shell.execute_reply.started":"2022-06-22T06:32:02.363625Z","shell.execute_reply":"2022-06-22T08:28:46.116278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# view results for each model\nevals","metadata":{"execution":{"iopub.status.busy":"2022-06-22T08:40:43.085047Z","iopub.execute_input":"2022-06-22T08:40:43.08604Z","iopub.status.idle":"2022-06-22T08:40:43.091459Z","shell.execute_reply.started":"2022-06-22T08:40:43.085991Z","shell.execute_reply":"2022-06-22T08:40:43.090714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Section 5: Predictions on test data","metadata":{}},{"cell_type":"code","source":"# define chunk size\nchunk_size = 50000\n\n\ndef score_test_data(full_df, chunk_size, model_obj, date_field, cat_features, num_features, fold):\n    \n    # print\n    clear_output(wait = True)\n    print(f'######### Prediction using model {fold+1} #########')\n    \n    # get list of unique customer ids\n    test_customer_ids = list(set(full_df['customer_ID'].to_arrow().to_pylist()))\n    \n    # create list of prediction dfs\n    chunk_pred_list = []\n    \n    # chunk count\n    chunk_count = 1\n    \n    # read data in chunks\n    for i in range(0, len(test_customer_ids), chunk_size):\n        \n        # print chunk counter\n        print(f'Processing chunk {chunk_count}')\n        \n        # get the customer id chunk\n        customer_id_chunk = test_customer_ids[i : i+chunk_size]\n        \n        # get the data chunk\n        chunk = full_df[full_df['customer_ID'].isin(customer_id_chunk)]\n        \n        # process the chunks\n        # step 1: change date string to date\n        chunk = stringToDate(chunk, date_field)\n        \n        # step 2: create features\n        chunk = createFeatures(chunk, cat_features, num_features)\n        \n        # convert to DMatrix (for XGBoost only)\n        dtest = xgb.DMatrix(chunk.drop(columns = 'customer_ID'))\n        \n        # make predictions\n        chunk_pred = model_obj.predict(data = dtest)\n        \n        # merge with customer ids\n        chunk_pred_df = cudf.DataFrame(data = {'customer_ID' : chunk['customer_ID'],\n                                               f'prediction_{fold+1}' : chunk_pred})\n        \n        # add to chunk prediction list\n        chunk_pred_list.append(chunk_pred_df)\n        \n        # increment chunk counter\n        chunk_count = chunk_count + 1\n        \n        # delete the chunk\n        del chunk, dtest, chunk_pred, chunk_pred_df\n        \n    # print statment\n    print('All chunks processed, merging individual chunks')\n    \n    # concatenate chunk predictions\n    df_test_pred = cudf.concat(chunk_pred_list)\n    \n    # return prediction df\n    return df_test_pred","metadata":{"execution":{"iopub.status.busy":"2022-06-22T09:43:00.462736Z","iopub.execute_input":"2022-06-22T09:43:00.463478Z","iopub.status.idle":"2022-06-22T09:43:00.473078Z","shell.execute_reply.started":"2022-06-22T09:43:00.463437Z","shell.execute_reply":"2022-06-22T09:43:00.472153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predictions on test data\n\npred_df_list = []\n\n# read the full df\nfull_df = cudf.read_parquet(test_X_path)\n\nfor fold in range(FOLDS):\n    \n    # load model\n    model_xgb_saved = xgb.Booster()\n    model_xgb_saved.load_model(f'../input/amex-default-prediction-v1/model_xgb_fold_{fold+1}_2022-06-22.json')\n    \n    # predictions on test data\n    df_test_pred = score_test_data(full_df, chunk_size, model_xgb_saved, date_field, cat_features, num_features, fold)\n    \n    # sort df\n    df_test_pred =  df_test_pred.sort_values(by = 'customer_ID')\n    \n    \n    # merge dfs\n    if fold == 0:\n        df_test_pred_full = df_test_pred.copy()\n        \n    else:\n        df_test_pred_full = cudf.merge(df_test_pred_full, df_test_pred, on = 'customer_ID')","metadata":{"execution":{"iopub.status.busy":"2022-06-22T09:43:02.009668Z","iopub.execute_input":"2022-06-22T09:43:02.010043Z","iopub.status.idle":"2022-06-22T09:56:53.905596Z","shell.execute_reply.started":"2022-06-22T09:43:02.010013Z","shell.execute_reply":"2022-06-22T09:56:53.904724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test_pred_full['prediction'] = df_test_pred_full.drop(columns = 'customer_ID').mean(axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T09:58:52.054861Z","iopub.execute_input":"2022-06-22T09:58:52.055457Z","iopub.status.idle":"2022-06-22T09:58:52.326397Z","shell.execute_reply.started":"2022-06-22T09:58:52.055419Z","shell.execute_reply":"2022-06-22T09:58:52.325573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test_pred_full = df_test_pred_full.drop(columns = ['prediction_1', 'prediction_2', 'prediction_3', 'prediction_4', 'prediction_5'])","metadata":{"execution":{"iopub.status.busy":"2022-06-22T10:01:53.191328Z","iopub.execute_input":"2022-06-22T10:01:53.191682Z","iopub.status.idle":"2022-06-22T10:01:53.207603Z","shell.execute_reply.started":"2022-06-22T10:01:53.191653Z","shell.execute_reply":"2022-06-22T10:01:53.206706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test_pred_full.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-22T10:02:00.830836Z","iopub.execute_input":"2022-06-22T10:02:00.831335Z","iopub.status.idle":"2022-06-22T10:02:00.855671Z","shell.execute_reply.started":"2022-06-22T10:02:00.831291Z","shell.execute_reply":"2022-06-22T10:02:00.854944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# output to csv\ndf_test_pred_full.to_csv(f'Amex predictions_{datetime.now()}.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T10:02:07.186883Z","iopub.execute_input":"2022-06-22T10:02:07.187409Z","iopub.status.idle":"2022-06-22T10:02:07.432647Z","shell.execute_reply.started":"2022-06-22T10:02:07.187373Z","shell.execute_reply":"2022-06-22T10:02:07.431566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}